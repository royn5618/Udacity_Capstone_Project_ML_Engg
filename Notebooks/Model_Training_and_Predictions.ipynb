{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:17:10.096414Z",
     "start_time": "2021-09-27T01:17:09.870792Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['font.size'] = 15\n",
    "\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "from wordcloud import ImageColorGenerator\n",
    "import contractions\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, QuantileTransformer, MinMaxScaler, MaxAbsScaler, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:17:11.276320Z",
     "start_time": "2021-09-27T01:17:11.056954Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/df_train_prepped.csv')\n",
    "df_test = pd.read_csv('../data/df_test_prepped.csv', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Names - STATIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I prefer standardizing column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:17:13.459642Z",
     "start_time": "2021-09-27T01:17:13.434659Z"
    }
   },
   "outputs": [],
   "source": [
    "KEYWORD = 'keyword'\n",
    "ID = 'id'\n",
    "LOCATION = 'location'\n",
    "TEXT = 'text'\n",
    "TARGET = 'target'\n",
    "TEXT_TOKENIZED = 'Text Tokenized'\n",
    "SENTIMENT = 'Sentiment Score'\n",
    "SENTIMENT_ROUND = 'Sentiment Score (rounded off)'\n",
    "_LOC_POINT = '_loc_point'\n",
    "WORDS_PER_TWEET = 'Words Per Tweet'\n",
    "CHAR_PER_TWEET = 'Characters Per Tweet'\n",
    "LOCATIONS = 'Locations'\n",
    "_LOC_SPACY_OBJ_ = 'Location Spacy Object'\n",
    "ALL_TEXT = 'all_text'\n",
    "ALL_TEXT_JOINED = 'all_text_joined'\n",
    "NUM_IN_TWEETS = 'Number in Tweet'\n",
    "PUNCTUATION_COUNT = 'Punctuation Count Per Tweet'\n",
    "IDENTIFIABLE_LOCATION = 'Identifiable Location'\n",
    "IN_BOW = 'Present In BOW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:17:15.321219Z",
     "start_time": "2021-09-27T01:17:15.278167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                  0\n",
       "keyword                            61\n",
       "location                         2533\n",
       "text                                0\n",
       "target                              0\n",
       "Punctuation Count Per Tweet         0\n",
       "Number in Tweet                     0\n",
       "Sentiment Score                     0\n",
       "Sentiment Score (rounded off)       0\n",
       "Text Tokenized                      0\n",
       "Words Per Tweet                     0\n",
       "Characters Per Tweet                0\n",
       "Present In BOW                      0\n",
       "Locations                           0\n",
       "Identifiable Location               0\n",
       "all_text                            0\n",
       "all_text_joined                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:17:16.473077Z",
     "start_time": "2021-09-27T01:17:16.442587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                  0\n",
       "keyword                            26\n",
       "location                         1105\n",
       "text                                1\n",
       "Punctuation Count Per Tweet         0\n",
       "Number in Tweet                     0\n",
       "Sentiment Score                     0\n",
       "Sentiment Score (rounded off)       0\n",
       "Locations                           0\n",
       "Identifiable Location               0\n",
       "Text Tokenized                      0\n",
       "Words Per Tweet                     0\n",
       "Characters Per Tweet                0\n",
       "Present In BOW                      0\n",
       "all_text                            0\n",
       "all_text_joined                     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:17:17.495947Z",
     "start_time": "2021-09-27T01:17:17.452216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                               0\n",
       "keyword                          0\n",
       "location                         0\n",
       "text                             0\n",
       "Punctuation Count Per Tweet      0\n",
       "Number in Tweet                  0\n",
       "Sentiment Score                  0\n",
       "Sentiment Score (rounded off)    0\n",
       "Locations                        0\n",
       "Identifiable Location            0\n",
       "Text Tokenized                   0\n",
       "Words Per Tweet                  0\n",
       "Characters Per Tweet             0\n",
       "Present In BOW                   0\n",
       "all_text                         0\n",
       "all_text_joined                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.fillna(' ', inplace=True)\n",
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Data Modeling Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:17:19.440810Z",
     "start_time": "2021-09-27T01:17:19.411190Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_classification_metrics(y_train, train_pred, y_test, test_pred):\n",
    "    print('Training Accuracy: ', accuracy_score(y_train, train_pred))\n",
    "    print('Training f1-score: ', f1_score(y_train, train_pred))\n",
    "    print('Accuracy: ', accuracy_score(y_test, test_pred))\n",
    "    print('Precision: ', precision_score(y_test, test_pred))\n",
    "    print('Recall: ', recall_score(y_test, test_pred))\n",
    "    print('f1-score: ', f1_score(y_test, test_pred))\n",
    "    \n",
    "def predict_challenge_test_data(model, test_data, filename):\n",
    "    submission_predictions = model.predict(test_data)\n",
    "    df_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "    df_submission[TARGET] = submission_predictions\n",
    "    df_submission.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:17:19.715491Z",
     "start_time": "2021-09-27T01:17:19.677345Z"
    }
   },
   "outputs": [],
   "source": [
    "DF_PERF_METRICS = pd.DataFrame(columns=[\n",
    "    'Model', 'Accuracy_Training_Set', 'Accuracy_Test_Set', 'Precision',\n",
    "    'Recall', 'f1_score', 'Training Time (secs)'\n",
    "])\n",
    "LIST_MODELS_TRAINED = []\n",
    "\n",
    "\n",
    "def get_perf_metrics(model, i):\n",
    "    # model name\n",
    "    model_name = type(model).__name__\n",
    "    # time keeping\n",
    "    start_time = time.time()\n",
    "    print(\"Training {} model...\".format(model_name))\n",
    "    # Fitting of model\n",
    "    model.fit(X_train_sparse, y_train)\n",
    "    print(\"Completed {} model training.\".format(model_name))\n",
    "    elapsed_time = time.time() - start_time\n",
    "    # Time Elapsed\n",
    "    print(\"Time elapsed: {:.2f} s.\".format(elapsed_time))\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_sparse)\n",
    "    # Add to ith row of dataframe - metrics\n",
    "    DF_PERF_METRICS.loc[i] = [\n",
    "        model_name,\n",
    "        model.score(X_train_sparse, y_train),\n",
    "        model.score(X_test_sparse, y_test),\n",
    "        precision_score(y_test, y_pred),\n",
    "        recall_score(y_test, y_pred),\n",
    "        f1_score(y_test, y_pred), \"{:.2f}\".format(elapsed_time)\n",
    "    ]\n",
    "    # keep a track of trained models\n",
    "    LIST_MODELS_TRAINED.append(model)\n",
    "    print(\"Completed {} model's performance assessment.\".format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have chosen to use only the joined text data, transformed using CountVectorizer and normalised using TfIdf Transformer. Logistic Regression is used for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:21.530818Z",
     "start_time": "2021-09-06T11:35:20.802099Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_to_train = [ALL_TEXT_JOINED]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train[cols_to_train],\n",
    "                                                    df_train[TARGET].values,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "pipe = Pipeline([('count_vec', CountVectorizer(ngram_range=(1, 2))),\n",
    "                 ('tf_idf', TfidfTransformer(smooth_idf=False))])\n",
    "ct = ColumnTransformer([('pipe', pipe, ALL_TEXT_JOINED)],\n",
    "                       remainder='passthrough')\n",
    "\n",
    "ct.fit(X_train)\n",
    "X_train_sparse = ct.transform(X_train)\n",
    "X_test_sparse = ct.transform(X_test)\n",
    "df_test_sparse = ct.transform(df_test[cols_to_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:22.201653Z",
     "start_time": "2021-09-06T11:35:21.530818Z"
    }
   },
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train_sparse, y_train)\n",
    "baseline_prediction = log_reg.predict(X_test_sparse)\n",
    "training_prediction = log_reg.predict(X_train_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:22.256574Z",
     "start_time": "2021-09-06T11:35:22.201653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9185550082101807\n",
      "Training f1-score:  0.8972659486329743\n",
      "Accuracy:  0.8003939592908733\n",
      "Precision:  0.8176795580110497\n",
      "Recall:  0.6841294298921418\n",
      "f1-score:  0.7449664429530202\n"
     ]
    }
   ],
   "source": [
    "print_classification_metrics(y_train, training_prediction, y_test, baseline_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:23.563672Z",
     "start_time": "2021-09-06T11:35:22.261522Z"
    }
   },
   "outputs": [],
   "source": [
    "model = log_reg.fit(ct.transform(df_train[cols_to_train]), df_train[TARGET].values)\n",
    "predict_challenge_test_data(model, df_test_sparse, '../Predictions/baseline_predictions_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "The training accuracy and f1-score is quite high as compared to the test (hold-out) accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Performance with CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, testing the performance without normalization using TfidfTransformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:24.932146Z",
     "start_time": "2021-09-06T11:35:23.563672Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_to_train = [ALL_TEXT_JOINED]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train[cols_to_train],\n",
    "                                                    df_train[TARGET].values,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "ct = ColumnTransformer([('count_vec', CountVectorizer(ngram_range=(1, 2)), ALL_TEXT_JOINED)],\n",
    "                       remainder='passthrough')\n",
    "\n",
    "ct.fit(X_train)\n",
    "X_train_sparse = ct.transform(X_train)\n",
    "X_test_sparse = ct.transform(X_test)\n",
    "df_test_sparse = ct.transform(df_test[cols_to_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:26.175241Z",
     "start_time": "2021-09-06T11:35:24.932146Z"
    }
   },
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_sparse, y_train)\n",
    "test_prediction = log_reg.predict(X_test_sparse)\n",
    "training_prediction = log_reg.predict(X_train_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:26.221638Z",
     "start_time": "2021-09-06T11:35:26.180215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9885057471264368\n",
      "Training f1-score:  0.9865591397849462\n",
      "Accuracy:  0.8017071569271176\n",
      "Precision:  0.8070796460176991\n",
      "Recall:  0.7026194144838213\n",
      "f1-score:  0.7512355848434925\n"
     ]
    }
   ],
   "source": [
    "print_classification_metrics(y_train, training_prediction, y_test, test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "There is improvement in the performance. Hence, I will continue to use only CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:28.055287Z",
     "start_time": "2021-09-06T11:35:26.221638Z"
    }
   },
   "outputs": [],
   "source": [
    "model = log_reg.fit(ct.transform(df_train[cols_to_train]), df_train[TARGET].values)\n",
    "predict_challenge_test_data(model, df_test_sparse, '../Predictions/test_predictions_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:29.449414Z",
     "start_time": "2021-09-06T11:35:28.055287Z"
    }
   },
   "outputs": [],
   "source": [
    "# TEST 1 - Using Rounded off Sentiment Score\n",
    "\n",
    "cols_to_train = [ALL_TEXT_JOINED, SENTIMENT_ROUND]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train[cols_to_train],\n",
    "                                                    df_train[TARGET].values,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "ct = ColumnTransformer([('count_vec', CountVectorizer(ngram_range=(1, 2)), ALL_TEXT_JOINED)],\n",
    "                       remainder='passthrough')\n",
    "\n",
    "ct.fit(X_train)\n",
    "X_train_sparse = ct.transform(X_train)\n",
    "X_test_sparse = ct.transform(X_test)\n",
    "df_test_sparse = ct.transform(df_test[cols_to_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:30.581446Z",
     "start_time": "2021-09-06T11:35:29.453369Z"
    }
   },
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_sparse, y_train)\n",
    "test_prediction = log_reg.predict(X_test_sparse)\n",
    "training_prediction = log_reg.predict(X_train_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:30.632938Z",
     "start_time": "2021-09-06T11:35:30.585677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9886699507389163\n",
      "Training f1-score:  0.9867536955269726\n",
      "Accuracy:  0.8003939592908733\n",
      "Precision:  0.8074866310160428\n",
      "Recall:  0.6979969183359014\n",
      "f1-score:  0.7487603305785123\n"
     ]
    }
   ],
   "source": [
    "print_classification_metrics(y_train, training_prediction, y_test, test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:31.983455Z",
     "start_time": "2021-09-06T11:35:30.637677Z"
    }
   },
   "outputs": [],
   "source": [
    "# TEST 2 - Using Raw Sentiment Score\n",
    "\n",
    "cols_to_train = [ALL_TEXT_JOINED, SENTIMENT]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train[cols_to_train],\n",
    "                                                    df_train[TARGET].values,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "ct = ColumnTransformer([('count_vec', CountVectorizer(ngram_range=(1, 2)), ALL_TEXT_JOINED)],\n",
    "                       remainder='passthrough')\n",
    "\n",
    "ct.fit(X_train)\n",
    "X_train_sparse = ct.transform(X_train)\n",
    "X_test_sparse = ct.transform(X_test)\n",
    "df_test_sparse = ct.transform(df_test[cols_to_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:33.156942Z",
     "start_time": "2021-09-06T11:35:31.988968Z"
    }
   },
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_sparse, y_train)\n",
    "test_prediction = log_reg.predict(X_test_sparse)\n",
    "training_prediction = log_reg.predict(X_train_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:33.210009Z",
     "start_time": "2021-09-06T11:35:33.156942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9886699507389163\n",
      "Training f1-score:  0.9867536955269726\n",
      "Accuracy:  0.7971109652002626\n",
      "Precision:  0.7992957746478874\n",
      "Recall:  0.699537750385208\n",
      "f1-score:  0.7460969597370584\n"
     ]
    }
   ],
   "source": [
    "print_classification_metrics(y_train, training_prediction, y_test, test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Other Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removed **characters per tweet** since it is strongly correlated with **words per tweet**. So, it doesn't make sense that I keep both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:33.255025Z",
     "start_time": "2021-09-06T11:35:33.220718Z"
    }
   },
   "outputs": [],
   "source": [
    "# TEST 1\n",
    "\n",
    "cols_to_train = [\n",
    "    ALL_TEXT_JOINED, SENTIMENT_ROUND, WORDS_PER_TWEET,\n",
    "    NUM_IN_TWEETS, PUNCTUATION_COUNT, IDENTIFIABLE_LOCATION, IN_BOW\n",
    "] # avg ~ 74\n",
    "\n",
    "# # TEST 2\n",
    "\n",
    "# cols_to_train = [\n",
    "#     ALL_TEXT_JOINED, SENTIMENT_ROUND, WORDS_PER_TWEET,\n",
    "#     NUM_IN_TWEETS, PUNCTUATION_COUNT, IDENTIFIABLE_LOCATION\n",
    "# ] # avg ~ 76\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train[cols_to_train],\n",
    "                                                    df_train[TARGET].values,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "cols_to_scale = [WORDS_PER_TWEET, PUNCTUATION_COUNT]\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [(\"scaler\", StandardScaler(), cols_to_scale),\n",
    "     ('count_vec', CountVectorizer(ngram_range=(1, 2)) , ALL_TEXT_JOINED)],\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:34.633661Z",
     "start_time": "2021-09-06T11:35:33.262702Z"
    }
   },
   "outputs": [],
   "source": [
    "ct.fit(X_train)\n",
    "X_train_sparse = ct.transform(X_train)\n",
    "X_test_sparse = ct.transform(X_test)\n",
    "df_test_sparse = ct.transform(df_test[cols_to_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:36.355598Z",
     "start_time": "2021-09-06T11:35:34.633661Z"
    }
   },
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_sparse, y_train)\n",
    "test_prediction = log_reg.predict(X_test_sparse)\n",
    "training_prediction = log_reg.predict(X_train_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:36.408074Z",
     "start_time": "2021-09-06T11:35:36.359457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9873563218390805\n",
      "Training f1-score:  0.9851894595114447\n",
      "Accuracy:  0.799080761654629\n",
      "Precision:  0.7941680960548885\n",
      "Recall:  0.7134052388289677\n",
      "f1-score:  0.7516233766233767\n"
     ]
    }
   ],
   "source": [
    "print_classification_metrics(y_train, training_prediction, y_test, test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T13:52:18.539022Z",
     "start_time": "2021-08-25T13:52:18.517051Z"
    }
   },
   "source": [
    "**Observations**\n",
    "\n",
    "The model performance decreases on adding all the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance using Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:36.440251Z",
     "start_time": "2021-09-06T11:35:36.409249Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_to_train = [\n",
    "    SENTIMENT_ROUND, WORDS_PER_TWEET,\n",
    "    NUM_IN_TWEETS, PUNCTUATION_COUNT, IDENTIFIABLE_LOCATION, IN_BOW\n",
    "]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train[cols_to_train],\n",
    "                                                    df_train[TARGET].values,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "cols_to_scale = [WORDS_PER_TWEET, PUNCTUATION_COUNT]\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [(\"scaler\", StandardScaler(), cols_to_scale)],\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:36.505377Z",
     "start_time": "2021-09-06T11:35:36.440251Z"
    }
   },
   "outputs": [],
   "source": [
    "ct.fit(X_train)\n",
    "X_train_sparse = ct.transform(X_train)\n",
    "X_test_sparse = ct.transform(X_test)\n",
    "df_test_sparse = ct.transform(df_test[cols_to_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:38.067229Z",
     "start_time": "2021-09-06T11:35:36.505876Z"
    }
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train_sparse, y_train)\n",
    "test_prediction = rfc.predict(X_test_sparse)\n",
    "training_prediction = rfc.predict(X_train_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:38.116575Z",
     "start_time": "2021-09-06T11:35:38.067229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.7354679802955665\n",
      "Training f1-score:  0.6530260607365928\n",
      "Accuracy:  0.6447800393959291\n",
      "Precision:  0.5989010989010989\n",
      "Recall:  0.5038520801232665\n",
      "f1-score:  0.5472803347280335\n"
     ]
    }
   ],
   "source": [
    "print_classification_metrics(y_train, training_prediction, y_test, test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:38.598926Z",
     "start_time": "2021-09-06T11:35:38.116575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=rfc.feature_importances_, y=cols_to_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "From this experiment, Sentiment, Words Per Tweet and IN BOW have stronger effect on the predictions. Therefore, I will be using them in the next set of tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Scaling Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:50.813674Z",
     "start_time": "2021-09-06T11:35:38.598926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler()\n",
      "Training Accuracy:  0.9875205254515599\n",
      "Training f1-score:  0.9853902345251827\n",
      "Accuracy:  0.8003939592908733\n",
      "Precision:  0.7928692699490663\n",
      "Recall:  0.7195685670261941\n",
      "f1-score:  0.7544426494345718\n",
      "-------------------------\n",
      "QuantileTransformer()\n",
      "Training Accuracy:  0.9875205254515599\n",
      "Training f1-score:  0.9853846153846155\n",
      "Accuracy:  0.799080761654629\n",
      "Precision:  0.7931623931623931\n",
      "Recall:  0.7149460708782742\n",
      "f1-score:  0.7520259319286872\n",
      "-------------------------\n",
      "MinMaxScaler()\n",
      "Training Accuracy:  0.9875205254515599\n",
      "Training f1-score:  0.9853902345251827\n",
      "Accuracy:  0.7984241628365069\n",
      "Precision:  0.7928082191780822\n",
      "Recall:  0.7134052388289677\n",
      "f1-score:  0.7510137875101379\n",
      "-------------------------\n",
      "MaxAbsScaler()\n",
      "Training Accuracy:  0.9875205254515599\n",
      "Training f1-score:  0.9853902345251827\n",
      "Accuracy:  0.799080761654629\n",
      "Precision:  0.7931623931623931\n",
      "Recall:  0.7149460708782742\n",
      "f1-score:  0.7520259319286872\n",
      "-------------------------\n",
      "RobustScaler()\n",
      "Training Accuracy:  0.9875205254515599\n",
      "Training f1-score:  0.9853902345251827\n",
      "Accuracy:  0.7997373604727511\n",
      "Precision:  0.7925170068027211\n",
      "Recall:  0.7180277349768875\n",
      "f1-score:  0.7534357316087307\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "list_scalers = [\n",
    "    StandardScaler(),\n",
    "    QuantileTransformer(),\n",
    "    MinMaxScaler(),\n",
    "    MaxAbsScaler(),\n",
    "    RobustScaler()\n",
    "]\n",
    "\n",
    "cols_to_train = [ALL_TEXT_JOINED, SENTIMENT_ROUND, WORDS_PER_TWEET, IN_BOW]\n",
    "cols_to_scale = [WORDS_PER_TWEET]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train[cols_to_train],\n",
    "                                                    df_train[TARGET].values,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "for scaler in list_scalers:\n",
    "    print(scaler)\n",
    "    ct = ColumnTransformer(\n",
    "        [(\"scaler\", scaler, cols_to_scale),\n",
    "         (\"count_vec\", CountVectorizer(ngram_range=(1, 2)), ALL_TEXT_JOINED)],\n",
    "        remainder='passthrough')\n",
    "\n",
    "    ct.fit(X_train)\n",
    "    X_train_sparse = ct.transform(X_train)\n",
    "    X_test_sparse = ct.transform(X_test)\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X_train_sparse, y_train)\n",
    "    test_prediction = log_reg.predict(X_test_sparse)\n",
    "    training_prediction = log_reg.predict(X_train_sparse)\n",
    "    print_classification_metrics(y_train, training_prediction, y_test,\n",
    "                                 test_prediction)\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T13:26:46.643520Z",
     "start_time": "2021-08-25T13:26:46.607601Z"
    }
   },
   "source": [
    "**Observations**\n",
    "\n",
    "The standard scaler is performing the best considering the f1-score of the hold-out test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Multiple Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:52.160751Z",
     "start_time": "2021-09-06T11:35:50.813674Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_to_train = [ALL_TEXT_JOINED, SENTIMENT_ROUND, WORDS_PER_TWEET, IN_BOW]\n",
    "cols_to_scale = [WORDS_PER_TWEET]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train[cols_to_train],\n",
    "                                                    df_train[TARGET].values,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "ct = ColumnTransformer(\n",
    "    [(\"scaler\", StandardScaler(), cols_to_scale),\n",
    "     (\"count_vec\", CountVectorizer(ngram_range=(1, 2)), ALL_TEXT_JOINED)],\n",
    "    remainder='passthrough')\n",
    "\n",
    "ct.fit(X_train)\n",
    "X_train_sparse = ct.transform(X_train)\n",
    "X_test_sparse = ct.transform(X_test)\n",
    "df_test_sparse = ct.transform(df_test[cols_to_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:35:52.176775Z",
     "start_time": "2021-09-06T11:35:52.160751Z"
    }
   },
   "outputs": [],
   "source": [
    "models_list = [LogisticRegression(),\n",
    "               SVC(),\n",
    "               KNeighborsClassifier(),\n",
    "               DecisionTreeClassifier(),\n",
    "               RandomForestClassifier(),\n",
    "               GradientBoostingClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:37:38.725481Z",
     "start_time": "2021-09-06T11:35:52.179318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LogisticRegression model...\n",
      "Completed LogisticRegression model training.\n",
      "Time elapsed: 1.50 s.\n",
      "Completed LogisticRegression model's performance assessment.\n",
      "Training SVC model...\n",
      "Completed SVC model training.\n",
      "Time elapsed: 16.87 s.\n",
      "Completed SVC model's performance assessment.\n",
      "Training KNeighborsClassifier model...\n",
      "Completed KNeighborsClassifier model training.\n",
      "Time elapsed: 0.00 s.\n",
      "Completed KNeighborsClassifier model's performance assessment.\n",
      "Training DecisionTreeClassifier model...\n",
      "Completed DecisionTreeClassifier model training.\n",
      "Time elapsed: 6.53 s.\n",
      "Completed DecisionTreeClassifier model's performance assessment.\n",
      "Training RandomForestClassifier model...\n",
      "Completed RandomForestClassifier model training.\n",
      "Time elapsed: 42.35 s.\n",
      "Completed RandomForestClassifier model's performance assessment.\n",
      "Training GradientBoostingClassifier model...\n",
      "Completed GradientBoostingClassifier model training.\n",
      "Time elapsed: 9.19 s.\n",
      "Completed GradientBoostingClassifier model's performance assessment.\n"
     ]
    }
   ],
   "source": [
    "for n, model in enumerate(models_list):\n",
    "    get_perf_metrics(model, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:37:38.772689Z",
     "start_time": "2021-09-06T11:37:38.725481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy_Training_Set</th>\n",
       "      <th>Accuracy_Test_Set</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>Training Time (secs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.987521</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.792869</td>\n",
       "      <td>0.719569</td>\n",
       "      <td>0.754443</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.957471</td>\n",
       "      <td>0.793828</td>\n",
       "      <td>0.837022</td>\n",
       "      <td>0.640986</td>\n",
       "      <td>0.726003</td>\n",
       "      <td>16.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.783415</td>\n",
       "      <td>0.714380</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.397535</td>\n",
       "      <td>0.542587</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.991461</td>\n",
       "      <td>0.746553</td>\n",
       "      <td>0.711755</td>\n",
       "      <td>0.681048</td>\n",
       "      <td>0.696063</td>\n",
       "      <td>6.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.991461</td>\n",
       "      <td>0.782666</td>\n",
       "      <td>0.816733</td>\n",
       "      <td>0.631741</td>\n",
       "      <td>0.712424</td>\n",
       "      <td>42.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.772250</td>\n",
       "      <td>0.742613</td>\n",
       "      <td>0.762781</td>\n",
       "      <td>0.574730</td>\n",
       "      <td>0.655536</td>\n",
       "      <td>9.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Accuracy_Training_Set  Accuracy_Test_Set  \\\n",
       "0          LogisticRegression               0.987521           0.800394   \n",
       "1                         SVC               0.957471           0.793828   \n",
       "2        KNeighborsClassifier               0.783415           0.714380   \n",
       "3      DecisionTreeClassifier               0.991461           0.746553   \n",
       "4      RandomForestClassifier               0.991461           0.782666   \n",
       "5  GradientBoostingClassifier               0.772250           0.742613   \n",
       "\n",
       "   Precision    Recall  f1_score Training Time (secs)  \n",
       "0   0.792869  0.719569  0.754443                 1.50  \n",
       "1   0.837022  0.640986  0.726003                16.87  \n",
       "2   0.854305  0.397535  0.542587                 0.00  \n",
       "3   0.711755  0.681048  0.696063                 6.53  \n",
       "4   0.816733  0.631741  0.712424                42.35  \n",
       "5   0.762781  0.574730  0.655536                 9.19  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_PERF_METRICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-25T21:21:54.488806Z",
     "start_time": "2021-07-25T21:21:54.463819Z"
    }
   },
   "source": [
    "# HyperParameter Tuning for Model Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proceeding onto tuning logistic regression since it has the best F1 score so far. I start with the a sparse set of values for max_iter and C.\n",
    "\n",
    "I am using the features  **ALL_TEXT_JOINED, SENTIMENT_ROUND, WORDS_PER_TWEET, IN_BOW**\n",
    "\n",
    "For  **WORDS_PER_TWEET**  is scaled using Standard Scaler and  **ALL_TEXT_JOINED**  is vectorized using CountVectorizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:28:29.579457Z",
     "start_time": "2021-09-27T01:28:28.845548Z"
    }
   },
   "outputs": [],
   "source": [
    "# Execute the data prep pipeline\n",
    "\n",
    "cols_to_train = [ALL_TEXT_JOINED, SENTIMENT_ROUND, WORDS_PER_TWEET, IN_BOW]\n",
    "cols_to_scale = [WORDS_PER_TWEET]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train[cols_to_train],\n",
    "                                                    df_train[TARGET].values,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "ct = ColumnTransformer(\n",
    "    [(\"scaler\", StandardScaler(), cols_to_scale),\n",
    "     (\"count_vec\", CountVectorizer(ngram_range=(1, 2)), ALL_TEXT_JOINED)],\n",
    "    remainder='passthrough')\n",
    "\n",
    "ct.fit(X_train)\n",
    "X_train_sparse = ct.transform(X_train)\n",
    "X_test_sparse = ct.transform(X_test)\n",
    "df_test_sparse = ct.transform(df_test[cols_to_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:30:20.192760Z",
     "start_time": "2021-09-27T01:28:30.322440Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5] END ...........C=0.1, max_iter=100; f1: (test=0.711) total time=   0.3s\n",
      "[CV 2/5] END ...........C=0.1, max_iter=100; f1: (test=0.728) total time=   0.3s\n",
      "[CV 3/5] END ...........C=0.1, max_iter=100; f1: (test=0.729) total time=   0.2s\n",
      "[CV 4/5] END ...........C=0.1, max_iter=100; f1: (test=0.705) total time=   0.3s\n",
      "[CV 5/5] END ...........C=0.1, max_iter=100; f1: (test=0.713) total time=   0.2s\n",
      "[CV 1/5] END ...........C=0.1, max_iter=200; f1: (test=0.711) total time=   0.3s\n",
      "[CV 2/5] END ...........C=0.1, max_iter=200; f1: (test=0.728) total time=   0.3s\n",
      "[CV 3/5] END ...........C=0.1, max_iter=200; f1: (test=0.729) total time=   0.2s\n",
      "[CV 4/5] END ...........C=0.1, max_iter=200; f1: (test=0.705) total time=   0.3s\n",
      "[CV 5/5] END ...........C=0.1, max_iter=200; f1: (test=0.713) total time=   0.2s\n",
      "[CV 1/5] END ...........C=0.1, max_iter=500; f1: (test=0.711) total time=   0.3s\n",
      "[CV 2/5] END ...........C=0.1, max_iter=500; f1: (test=0.728) total time=   0.3s\n",
      "[CV 3/5] END ...........C=0.1, max_iter=500; f1: (test=0.729) total time=   0.2s\n",
      "[CV 4/5] END ...........C=0.1, max_iter=500; f1: (test=0.705) total time=   0.3s\n",
      "[CV 5/5] END ...........C=0.1, max_iter=500; f1: (test=0.713) total time=   0.2s\n",
      "[CV 1/5] END ..........C=0.1, max_iter=1000; f1: (test=0.711) total time=   0.4s\n",
      "[CV 2/5] END ..........C=0.1, max_iter=1000; f1: (test=0.728) total time=   0.3s\n",
      "[CV 3/5] END ..........C=0.1, max_iter=1000; f1: (test=0.729) total time=   0.2s\n",
      "[CV 4/5] END ..........C=0.1, max_iter=1000; f1: (test=0.705) total time=   0.3s\n",
      "[CV 5/5] END ..........C=0.1, max_iter=1000; f1: (test=0.713) total time=   0.2s\n",
      "[CV 1/5] END ...........C=0.5, max_iter=100; f1: (test=0.737) total time=   0.5s\n",
      "[CV 2/5] END ...........C=0.5, max_iter=100; f1: (test=0.729) total time=   0.4s\n",
      "[CV 3/5] END ...........C=0.5, max_iter=100; f1: (test=0.757) total time=   0.4s\n",
      "[CV 4/5] END ...........C=0.5, max_iter=100; f1: (test=0.732) total time=   0.5s\n",
      "[CV 5/5] END ...........C=0.5, max_iter=100; f1: (test=0.738) total time=   0.3s\n",
      "[CV 1/5] END ...........C=0.5, max_iter=200; f1: (test=0.737) total time=   0.4s\n",
      "[CV 2/5] END ...........C=0.5, max_iter=200; f1: (test=0.729) total time=   0.5s\n",
      "[CV 3/5] END ...........C=0.5, max_iter=200; f1: (test=0.757) total time=   0.4s\n",
      "[CV 4/5] END ...........C=0.5, max_iter=200; f1: (test=0.732) total time=   0.5s\n",
      "[CV 5/5] END ...........C=0.5, max_iter=200; f1: (test=0.738) total time=   0.3s\n",
      "[CV 1/5] END ...........C=0.5, max_iter=500; f1: (test=0.737) total time=   0.5s\n",
      "[CV 2/5] END ...........C=0.5, max_iter=500; f1: (test=0.729) total time=   0.5s\n",
      "[CV 3/5] END ...........C=0.5, max_iter=500; f1: (test=0.757) total time=   0.4s\n",
      "[CV 4/5] END ...........C=0.5, max_iter=500; f1: (test=0.732) total time=   0.4s\n",
      "[CV 5/5] END ...........C=0.5, max_iter=500; f1: (test=0.738) total time=   0.4s\n",
      "[CV 1/5] END ..........C=0.5, max_iter=1000; f1: (test=0.737) total time=   0.5s\n",
      "[CV 2/5] END ..........C=0.5, max_iter=1000; f1: (test=0.729) total time=   0.4s\n",
      "[CV 3/5] END ..........C=0.5, max_iter=1000; f1: (test=0.757) total time=   0.3s\n",
      "[CV 4/5] END ..........C=0.5, max_iter=1000; f1: (test=0.732) total time=   0.4s\n",
      "[CV 5/5] END ..........C=0.5, max_iter=1000; f1: (test=0.738) total time=   0.3s\n",
      "[CV 1/5] END .............C=1, max_iter=100; f1: (test=0.743) total time=   0.6s\n",
      "[CV 2/5] END .............C=1, max_iter=100; f1: (test=0.724) total time=   0.5s\n",
      "[CV 3/5] END .............C=1, max_iter=100; f1: (test=0.758) total time=   0.5s\n",
      "[CV 4/5] END .............C=1, max_iter=100; f1: (test=0.740) total time=   0.6s\n",
      "[CV 5/5] END .............C=1, max_iter=100; f1: (test=0.741) total time=   0.4s\n",
      "[CV 1/5] END .............C=1, max_iter=200; f1: (test=0.743) total time=   0.6s\n",
      "[CV 2/5] END .............C=1, max_iter=200; f1: (test=0.724) total time=   0.6s\n",
      "[CV 3/5] END .............C=1, max_iter=200; f1: (test=0.758) total time=   0.4s\n",
      "[CV 4/5] END .............C=1, max_iter=200; f1: (test=0.740) total time=   0.6s\n",
      "[CV 5/5] END .............C=1, max_iter=200; f1: (test=0.741) total time=   0.4s\n",
      "[CV 1/5] END .............C=1, max_iter=500; f1: (test=0.743) total time=   0.6s\n",
      "[CV 2/5] END .............C=1, max_iter=500; f1: (test=0.724) total time=   0.5s\n",
      "[CV 3/5] END .............C=1, max_iter=500; f1: (test=0.758) total time=   0.4s\n",
      "[CV 4/5] END .............C=1, max_iter=500; f1: (test=0.740) total time=   0.5s\n",
      "[CV 5/5] END .............C=1, max_iter=500; f1: (test=0.741) total time=   0.4s\n",
      "[CV 1/5] END ............C=1, max_iter=1000; f1: (test=0.743) total time=   0.6s\n",
      "[CV 2/5] END ............C=1, max_iter=1000; f1: (test=0.724) total time=   0.5s\n",
      "[CV 3/5] END ............C=1, max_iter=1000; f1: (test=0.758) total time=   0.5s\n",
      "[CV 4/5] END ............C=1, max_iter=1000; f1: (test=0.740) total time=   0.5s\n",
      "[CV 5/5] END ............C=1, max_iter=1000; f1: (test=0.741) total time=   0.4s\n",
      "[CV 1/5] END ............C=10, max_iter=100; f1: (test=0.737) total time=   0.8s\n",
      "[CV 2/5] END ............C=10, max_iter=100; f1: (test=0.733) total time=   0.7s\n",
      "[CV 3/5] END ............C=10, max_iter=100; f1: (test=0.751) total time=   0.6s\n",
      "[CV 4/5] END ............C=10, max_iter=100; f1: (test=0.735) total time=   0.8s\n",
      "[CV 5/5] END ............C=10, max_iter=100; f1: (test=0.735) total time=   0.7s\n",
      "[CV 1/5] END ............C=10, max_iter=200; f1: (test=0.737) total time=   1.0s\n",
      "[CV 2/5] END ............C=10, max_iter=200; f1: (test=0.733) total time=   1.0s\n",
      "[CV 3/5] END ............C=10, max_iter=200; f1: (test=0.750) total time=   0.9s\n",
      "[CV 4/5] END ............C=10, max_iter=200; f1: (test=0.735) total time=   1.0s\n",
      "[CV 5/5] END ............C=10, max_iter=200; f1: (test=0.735) total time=   0.9s\n",
      "[CV 1/5] END ............C=10, max_iter=500; f1: (test=0.737) total time=   0.9s\n",
      "[CV 2/5] END ............C=10, max_iter=500; f1: (test=0.733) total time=   1.1s\n",
      "[CV 3/5] END ............C=10, max_iter=500; f1: (test=0.750) total time=   1.0s\n",
      "[CV 4/5] END ............C=10, max_iter=500; f1: (test=0.735) total time=   1.0s\n",
      "[CV 5/5] END ............C=10, max_iter=500; f1: (test=0.735) total time=   0.9s\n",
      "[CV 1/5] END ...........C=10, max_iter=1000; f1: (test=0.737) total time=   1.0s\n",
      "[CV 2/5] END ...........C=10, max_iter=1000; f1: (test=0.733) total time=   1.0s\n",
      "[CV 3/5] END ...........C=10, max_iter=1000; f1: (test=0.750) total time=   0.9s\n",
      "[CV 4/5] END ...........C=10, max_iter=1000; f1: (test=0.735) total time=   0.9s\n",
      "[CV 5/5] END ...........C=10, max_iter=1000; f1: (test=0.735) total time=   0.9s\n",
      "[CV 1/5] END ............C=50, max_iter=100; f1: (test=0.735) total time=   0.7s\n",
      "[CV 2/5] END ............C=50, max_iter=100; f1: (test=0.730) total time=   0.7s\n",
      "[CV 3/5] END ............C=50, max_iter=100; f1: (test=0.748) total time=   0.6s\n",
      "[CV 4/5] END ............C=50, max_iter=100; f1: (test=0.731) total time=   0.7s\n",
      "[CV 5/5] END ............C=50, max_iter=100; f1: (test=0.736) total time=   0.6s\n",
      "[CV 1/5] END ............C=50, max_iter=200; f1: (test=0.732) total time=   1.4s\n",
      "[CV 2/5] END ............C=50, max_iter=200; f1: (test=0.728) total time=   1.4s\n",
      "[CV 3/5] END ............C=50, max_iter=200; f1: (test=0.747) total time=   1.3s\n",
      "[CV 4/5] END ............C=50, max_iter=200; f1: (test=0.732) total time=   1.5s\n",
      "[CV 5/5] END ............C=50, max_iter=200; f1: (test=0.739) total time=   1.3s\n",
      "[CV 1/5] END ............C=50, max_iter=500; f1: (test=0.732) total time=   1.5s\n",
      "[CV 2/5] END ............C=50, max_iter=500; f1: (test=0.728) total time=   1.7s\n",
      "[CV 3/5] END ............C=50, max_iter=500; f1: (test=0.747) total time=   1.6s\n",
      "[CV 4/5] END ............C=50, max_iter=500; f1: (test=0.732) total time=   1.5s\n",
      "[CV 5/5] END ............C=50, max_iter=500; f1: (test=0.739) total time=   1.6s\n",
      "[CV 1/5] END ...........C=50, max_iter=1000; f1: (test=0.732) total time=   1.6s\n",
      "[CV 2/5] END ...........C=50, max_iter=1000; f1: (test=0.728) total time=   1.6s\n",
      "[CV 3/5] END ...........C=50, max_iter=1000; f1: (test=0.747) total time=   1.6s\n",
      "[CV 4/5] END ...........C=50, max_iter=1000; f1: (test=0.732) total time=   1.5s\n",
      "[CV 5/5] END ...........C=50, max_iter=1000; f1: (test=0.739) total time=   1.5s\n",
      "[CV 1/5] END ...........C=100, max_iter=100; f1: (test=0.733) total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...........C=100, max_iter=100; f1: (test=0.728) total time=   0.7s\n",
      "[CV 3/5] END ...........C=100, max_iter=100; f1: (test=0.745) total time=   0.6s\n",
      "[CV 4/5] END ...........C=100, max_iter=100; f1: (test=0.730) total time=   0.8s\n",
      "[CV 5/5] END ...........C=100, max_iter=100; f1: (test=0.740) total time=   0.6s\n",
      "[CV 1/5] END ...........C=100, max_iter=200; f1: (test=0.733) total time=   1.4s\n",
      "[CV 2/5] END ...........C=100, max_iter=200; f1: (test=0.727) total time=   1.4s\n",
      "[CV 3/5] END ...........C=100, max_iter=200; f1: (test=0.747) total time=   1.3s\n",
      "[CV 4/5] END ...........C=100, max_iter=200; f1: (test=0.732) total time=   1.4s\n",
      "[CV 5/5] END ...........C=100, max_iter=200; f1: (test=0.739) total time=   1.3s\n",
      "[CV 1/5] END ...........C=100, max_iter=500; f1: (test=0.732) total time=   2.2s\n",
      "[CV 2/5] END ...........C=100, max_iter=500; f1: (test=0.727) total time=   1.9s\n",
      "[CV 3/5] END ...........C=100, max_iter=500; f1: (test=0.745) total time=   1.7s\n",
      "[CV 4/5] END ...........C=100, max_iter=500; f1: (test=0.731) total time=   1.8s\n",
      "[CV 5/5] END ...........C=100, max_iter=500; f1: (test=0.739) total time=   1.9s\n",
      "[CV 1/5] END ..........C=100, max_iter=1000; f1: (test=0.732) total time=   2.1s\n",
      "[CV 2/5] END ..........C=100, max_iter=1000; f1: (test=0.727) total time=   2.0s\n",
      "[CV 3/5] END ..........C=100, max_iter=1000; f1: (test=0.745) total time=   1.9s\n",
      "[CV 4/5] END ..........C=100, max_iter=1000; f1: (test=0.731) total time=   1.8s\n",
      "[CV 5/5] END ..........C=100, max_iter=1000; f1: (test=0.739) total time=   2.0s\n"
     ]
    }
   ],
   "source": [
    "max_iter = [100, 200, 500, 1000]\n",
    "C = [0.1, 0.5, 1, 10, 50, 100]\n",
    "\n",
    "param_grid = dict(max_iter=max_iter, C=C)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "grid = GridSearchCV(estimator=logreg,\n",
    "                    param_grid=param_grid,\n",
    "                    cv=5,\n",
    "                    scoring=['f1'],\n",
    "                    refit='f1',\n",
    "                    verbose=3)\n",
    "\n",
    "grid_result = grid.fit(X_train_sparse, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:30:20.344498Z",
     "start_time": "2021-09-27T01:30:20.312915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9857142857142858\n",
      "Training f1-score:  0.9832531280076998\n",
      "Accuracy:  0.7977675640183848\n",
      "Precision:  0.7934595524956971\n",
      "Recall:  0.7103235747303543\n",
      "f1-score:  0.7495934959349594\n"
     ]
    }
   ],
   "source": [
    "model_1 = grid_result.best_estimator_\n",
    "y_pred_attempt_1 = model_1.predict(X_test_sparse)\n",
    "training_prediction = model_1.predict(X_train_sparse)\n",
    "print_classification_metrics(y_train, training_prediction, y_test, y_pred_attempt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:30:20.492685Z",
     "start_time": "2021-09-27T01:30:20.484955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'max_iter': 100}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atempt 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this attempt, I have narrowed down the grid values where the middle value is the previous best hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:43:54.340714Z",
     "start_time": "2021-09-27T01:43:22.876882Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END ..............C=1, max_iter=50; f1: (test=0.742) total time=   0.5s\n",
      "[CV 2/5] END ..............C=1, max_iter=50; f1: (test=0.724) total time=   0.3s\n",
      "[CV 3/5] END ..............C=1, max_iter=50; f1: (test=0.758) total time=   0.4s\n",
      "[CV 4/5] END ..............C=1, max_iter=50; f1: (test=0.740) total time=   0.3s\n",
      "[CV 5/5] END ..............C=1, max_iter=50; f1: (test=0.741) total time=   0.4s\n",
      "[CV 1/5] END .............C=1, max_iter=100; f1: (test=0.743) total time=   0.6s\n",
      "[CV 2/5] END .............C=1, max_iter=100; f1: (test=0.724) total time=   0.4s\n",
      "[CV 3/5] END .............C=1, max_iter=100; f1: (test=0.758) total time=   0.5s\n",
      "[CV 4/5] END .............C=1, max_iter=100; f1: (test=0.740) total time=   0.4s\n",
      "[CV 5/5] END .............C=1, max_iter=100; f1: (test=0.741) total time=   0.5s\n",
      "[CV 1/5] END .............C=1, max_iter=150; f1: (test=0.743) total time=   0.6s\n",
      "[CV 2/5] END .............C=1, max_iter=150; f1: (test=0.724) total time=   0.5s\n",
      "[CV 3/5] END .............C=1, max_iter=150; f1: (test=0.758) total time=   0.6s\n",
      "[CV 4/5] END .............C=1, max_iter=150; f1: (test=0.740) total time=   0.4s\n",
      "[CV 5/5] END .............C=1, max_iter=150; f1: (test=0.741) total time=   0.5s\n",
      "[CV 1/5] END ..............C=5, max_iter=50; f1: (test=0.737) total time=   0.4s\n",
      "[CV 2/5] END ..............C=5, max_iter=50; f1: (test=0.732) total time=   0.3s\n",
      "[CV 3/5] END ..............C=5, max_iter=50; f1: (test=0.752) total time=   0.4s\n",
      "[CV 4/5] END ..............C=5, max_iter=50; f1: (test=0.737) total time=   0.3s\n",
      "[CV 5/5] END ..............C=5, max_iter=50; f1: (test=0.736) total time=   0.4s\n",
      "[CV 1/5] END .............C=5, max_iter=100; f1: (test=0.738) total time=   0.7s\n",
      "[CV 2/5] END .............C=5, max_iter=100; f1: (test=0.731) total time=   0.6s\n",
      "[CV 3/5] END .............C=5, max_iter=100; f1: (test=0.754) total time=   0.7s\n",
      "[CV 4/5] END .............C=5, max_iter=100; f1: (test=0.737) total time=   0.7s\n",
      "[CV 5/5] END .............C=5, max_iter=100; f1: (test=0.737) total time=   0.8s\n",
      "[CV 1/5] END .............C=5, max_iter=150; f1: (test=0.738) total time=   1.0s\n",
      "[CV 2/5] END .............C=5, max_iter=150; f1: (test=0.731) total time=   0.7s\n",
      "[CV 3/5] END .............C=5, max_iter=150; f1: (test=0.754) total time=   0.8s\n",
      "[CV 4/5] END .............C=5, max_iter=150; f1: (test=0.737) total time=   0.6s\n",
      "[CV 5/5] END .............C=5, max_iter=150; f1: (test=0.737) total time=   0.9s\n",
      "[CV 1/5] END .............C=10, max_iter=50; f1: (test=0.737) total time=   0.4s\n",
      "[CV 2/5] END .............C=10, max_iter=50; f1: (test=0.737) total time=   0.4s\n",
      "[CV 3/5] END .............C=10, max_iter=50; f1: (test=0.754) total time=   0.4s\n",
      "[CV 4/5] END .............C=10, max_iter=50; f1: (test=0.737) total time=   0.3s\n",
      "[CV 5/5] END .............C=10, max_iter=50; f1: (test=0.731) total time=   0.4s\n",
      "[CV 1/5] END ............C=10, max_iter=100; f1: (test=0.737) total time=   0.7s\n",
      "[CV 2/5] END ............C=10, max_iter=100; f1: (test=0.733) total time=   0.6s\n",
      "[CV 3/5] END ............C=10, max_iter=100; f1: (test=0.751) total time=   0.8s\n",
      "[CV 4/5] END ............C=10, max_iter=100; f1: (test=0.735) total time=   0.6s\n",
      "[CV 5/5] END ............C=10, max_iter=100; f1: (test=0.735) total time=   0.7s\n",
      "[CV 1/5] END ............C=10, max_iter=150; f1: (test=0.737) total time=   0.9s\n",
      "[CV 2/5] END ............C=10, max_iter=150; f1: (test=0.733) total time=   0.9s\n",
      "[CV 3/5] END ............C=10, max_iter=150; f1: (test=0.750) total time=   1.1s\n",
      "[CV 4/5] END ............C=10, max_iter=150; f1: (test=0.735) total time=   0.9s\n",
      "[CV 5/5] END ............C=10, max_iter=150; f1: (test=0.735) total time=   1.0s\n"
     ]
    }
   ],
   "source": [
    "max_iter = [50, 100, 150]\n",
    "C = [1, 5, 10]\n",
    "\n",
    "param_grid = dict(max_iter=max_iter, C=C)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "grid = GridSearchCV(estimator=logreg,\n",
    "                    param_grid=param_grid,\n",
    "                    cv=5,\n",
    "                    scoring=['f1'],\n",
    "                    refit='f1',\n",
    "                    verbose=3)\n",
    "\n",
    "grid_result = grid.fit(X_train_sparse, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:43:56.890255Z",
     "start_time": "2021-09-27T01:43:56.841401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9857142857142858\n",
      "Training f1-score:  0.9832531280076998\n",
      "Accuracy:  0.7977675640183848\n",
      "Precision:  0.7934595524956971\n",
      "Recall:  0.7103235747303543\n",
      "f1-score:  0.7495934959349594\n"
     ]
    }
   ],
   "source": [
    "model_2 = grid_result.best_estimator_\n",
    "y_pred_attempt_2 = model_2.predict(X_test_sparse)\n",
    "training_prediction = model_2.predict(X_train_sparse)\n",
    "print_classification_metrics(y_train, training_prediction, y_test, y_pred_attempt_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:43:58.800461Z",
     "start_time": "2021-09-27T01:43:58.773524Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'max_iter': 100}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this attempt, I tried different combinations of penalty, solver and fit_intercept to check if they could predict better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:45:53.418641Z",
     "start_time": "2021-09-27T01:45:03.102475Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV 1/5] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga; f1: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga; f1: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga; f1: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga; f1: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga; f1: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear; f1: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear; f1: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear; f1: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear; f1: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear; f1: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs; f1: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs; f1: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs; f1: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs; f1: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs; f1: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga; f1: (test=0.733) total time=   3.7s\n",
      "[CV 2/5] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga; f1: (test=0.740) total time=   4.0s\n",
      "[CV 3/5] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga; f1: (test=0.751) total time=   3.9s\n",
      "[CV 4/5] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga; f1: (test=0.729) total time=   3.1s\n",
      "[CV 5/5] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga; f1: (test=0.748) total time=   4.0s\n",
      "[CV 1/5] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear; f1: (test=0.724) total time=   0.0s\n",
      "[CV 2/5] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear; f1: (test=0.735) total time=   0.0s\n",
      "[CV 3/5] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear; f1: (test=0.748) total time=   0.0s\n",
      "[CV 4/5] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear; f1: (test=0.720) total time=   0.0s\n",
      "[CV 5/5] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear; f1: (test=0.742) total time=   0.0s\n",
      "[CV 1/5] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs; f1: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs; f1: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs; f1: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs; f1: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs; f1: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga; f1: (test=0.750) total time=   0.3s\n",
      "[CV 2/5] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga; f1: (test=0.733) total time=   0.3s\n",
      "[CV 3/5] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga; f1: (test=0.763) total time=   0.3s\n",
      "[CV 4/5] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga; f1: (test=0.743) total time=   0.3s\n",
      "[CV 5/5] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga; f1: (test=0.752) total time=   0.3s\n",
      "[CV 1/5] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear; f1: (test=0.744) total time=   0.0s\n",
      "[CV 2/5] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear; f1: (test=0.724) total time=   0.0s\n",
      "[CV 3/5] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear; f1: (test=0.758) total time=   0.0s\n",
      "[CV 4/5] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear; f1: (test=0.740) total time=   0.0s\n",
      "[CV 5/5] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear; f1: (test=0.741) total time=   0.0s\n",
      "[CV 1/5] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs; f1: (test=0.743) total time=   0.5s\n",
      "[CV 2/5] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs; f1: (test=0.724) total time=   0.6s\n",
      "[CV 3/5] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs; f1: (test=0.758) total time=   0.4s\n",
      "[CV 4/5] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs; f1: (test=0.740) total time=   0.5s\n",
      "[CV 5/5] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs; f1: (test=0.741) total time=   0.4s\n",
      "[CV 1/5] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga; f1: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga; f1: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga; f1: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga; f1: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga; f1: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear; f1: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear; f1: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear; f1: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear; f1: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear; f1: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs; f1: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs; f1: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs; f1: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs; f1: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs; f1: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga; f1: (test=0.742) total time=   3.9s\n",
      "[CV 2/5] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga; f1: (test=0.740) total time=   4.2s\n",
      "[CV 3/5] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga; f1: (test=0.743) total time=   4.0s\n",
      "[CV 4/5] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga; f1: (test=0.724) total time=   3.0s\n",
      "[CV 5/5] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga; f1: (test=0.749) total time=   4.0s\n",
      "[CV 1/5] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear; f1: (test=0.734) total time=   0.0s\n",
      "[CV 2/5] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear; f1: (test=0.737) total time=   0.0s\n",
      "[CV 3/5] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear; f1: (test=0.745) total time=   0.0s\n",
      "[CV 4/5] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear; f1: (test=0.730) total time=   0.0s\n",
      "[CV 5/5] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear; f1: (test=0.748) total time=   0.0s\n",
      "[CV 1/5] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs; f1: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs; f1: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs; f1: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs; f1: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs; f1: (test=nan) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga; f1: (test=0.746) total time=   0.3s\n",
      "[CV 2/5] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga; f1: (test=0.738) total time=   0.2s\n",
      "[CV 3/5] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga; f1: (test=0.760) total time=   0.3s\n",
      "[CV 4/5] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga; f1: (test=0.743) total time=   0.3s\n",
      "[CV 5/5] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga; f1: (test=0.750) total time=   0.2s\n",
      "[CV 1/5] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear; f1: (test=0.745) total time=   0.0s\n",
      "[CV 2/5] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear; f1: (test=0.733) total time=   0.0s\n",
      "[CV 3/5] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear; f1: (test=0.757) total time=   0.0s\n",
      "[CV 4/5] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear; f1: (test=0.743) total time=   0.0s\n",
      "[CV 5/5] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear; f1: (test=0.752) total time=   0.0s\n",
      "[CV 1/5] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs; f1: (test=0.745) total time=   0.5s\n",
      "[CV 2/5] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs; f1: (test=0.733) total time=   0.5s\n",
      "[CV 3/5] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs; f1: (test=0.757) total time=   0.4s\n",
      "[CV 4/5] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs; f1: (test=0.742) total time=   0.5s\n",
      "[CV 5/5] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs; f1: (test=0.752) total time=   0.5s\n"
     ]
    }
   ],
   "source": [
    "penalty = ['elasticnet', 'l1', 'l2']\n",
    "solver = ['saga', 'liblinear', 'lbfgs']\n",
    "max_iter = [100]\n",
    "C = [1]\n",
    "fit_intercept = [True, False]\n",
    "\n",
    "param_grid = dict(max_iter=max_iter,\n",
    "                  C=C,\n",
    "                  penalty=penalty,\n",
    "                  solver=solver,\n",
    "                  fit_intercept=fit_intercept)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "grid = GridSearchCV(estimator=logreg,\n",
    "                    param_grid=param_grid,\n",
    "                    cv=5,\n",
    "                    scoring=['f1'],\n",
    "                    refit='f1',\n",
    "                    verbose=3)\n",
    "\n",
    "grid_result = grid.fit(X_train_sparse, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:46:01.748025Z",
     "start_time": "2021-09-27T01:46:01.705892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9768472906403941\n",
      "Training f1-score:  0.9726372986609741\n",
      "Accuracy:  0.799080761654629\n",
      "Precision:  0.7816091954022989\n",
      "Recall:  0.7334360554699538\n",
      "f1-score:  0.7567567567567569\n"
     ]
    }
   ],
   "source": [
    "model_3 = grid_result.best_estimator_\n",
    "y_pred_attempt_3 = model_3.predict(X_test_sparse)\n",
    "training_prediction = model_3.predict(X_train_sparse)\n",
    "print_classification_metrics(y_train, training_prediction, y_test, y_pred_attempt_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:46:03.805742Z",
     "start_time": "2021-09-27T01:46:03.794741Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1,\n",
       " 'fit_intercept': True,\n",
       " 'max_iter': 100,\n",
       " 'penalty': 'l2',\n",
       " 'solver': 'saga'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best results were with default hyperparameters of Logistic Regression. The features included the selected features, where words_per_tweet was scaled using StandardScalar, and the the text data vectorized using CountVectorizer.\n",
    "\n",
    "On tuning the algorithm, the best results are obtained using - \n",
    " \n",
    "``'C': 10,\n",
    " 'fit_intercept': False,\n",
    " 'max_iter': 100,\n",
    " 'penalty': 'l1',\n",
    " 'solver': 'saga'``\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:46:34.020711Z",
     "start_time": "2021-09-27T01:46:32.951271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, fit_intercept=False, solver='saga')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_train = [ALL_TEXT_JOINED, SENTIMENT_ROUND, WORDS_PER_TWEET, IN_BOW]\n",
    "cols_to_scale = [WORDS_PER_TWEET]\n",
    "\n",
    "X, y = df_train[cols_to_train], df_train[TARGET].values\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [(\"scaler\", StandardScaler(), cols_to_scale),\n",
    "     (\"count_vec\", CountVectorizer(ngram_range=(1, 2)), ALL_TEXT_JOINED)],\n",
    "    remainder='passthrough')\n",
    "\n",
    "ct.fit(X)\n",
    "X_sparse = ct.transform(X)\n",
    "\n",
    "final_model = LogisticRegression(C=1,\n",
    "                                 max_iter=100,\n",
    "                                 fit_intercept=False,\n",
    "                                 penalty='l2',\n",
    "                                 solver='saga')\n",
    "\n",
    "final_model.fit(X_sparse, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:46:36.510233Z",
     "start_time": "2021-09-27T01:46:36.486910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.97\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy: ', round(final_model.score(X_sparse, y), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:46:39.879535Z",
     "start_time": "2021-09-27T01:46:39.676745Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test_sparse = ct.transform(df_test[cols_to_train])\n",
    "predict_challenge_test_data(final_model, df_test_sparse, '../Predictions/final_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:46:42.087429Z",
     "start_time": "2021-09-27T01:46:42.077100Z"
    }
   },
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:46:43.238205Z",
     "start_time": "2021-09-27T01:46:43.217596Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/model.sav']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(final_model, '../model/model.sav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "300.792px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
